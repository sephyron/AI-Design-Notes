# AI-Design-Notes

### Human in the loop checklist
1. Clear Role Definition: Clearly communicate the roles and responsibilities of both the AI and human components to set expectations and avoid confusion.
2. Real-time Collaboration: Enable real-time communication and collaboration between human users and the AI system to facilitate efficient teamwork.
3. Contextual Assistance: Provide AI-generated suggestions, recommendations, or insights that are relevant to the user's current task or context, without being obtrusive.
4. Explainable AI: Present the reasoning behind AI-generated decisions or recommendations in an easily understandable manner to help users trust and build confidence in the AI system.
5. Feedback and Confirmation: Offer users clear feedback on their actions and confirmations for critical tasks, ensuring that they understand the impact of their decisions.
6. User Control and Override: Allow users to adjust, correct, or override AI-generated suggestions or decisions, reinforcing a sense of control and responsibility.
7. Visualizations: Use visual aids, such as charts, graphs, or heat maps, to represent AI-generated data or insights, making it easier for users to comprehend and act upon them.
8. Adaptive Learning: Ensure that the AI system learns from human input and feedback, continuously improving its performance and adapting to the user's needs and preferences.
9. Performance Metrics and Evaluation: Provide users with performance metrics and evaluation tools to help them understand the effectiveness of their collaboration with the AI system and identify areas for improvement.
10. Progressive Skill Development: Offer training, tutorials, or guided experiences to help users develop their skills and understanding of the AI system over time.
11. Fairness and Bias Reduction: By involving humans in decision-making processes or in the review of AI-generated outputs, human in the loop principles can catch and correct instances where the AI might otherwise perpetuate biases present in the training data. Humans can provide nuanced judgment in areas where AI systems might be too rigid or blind to social contexts. Humans can also help identify situations where AI decisions might be considered unfair or discriminatory. By reviewing these decisions in context, humans can offer a more holistic evaluation of fairness. If bias is detected and corrected repeatedly, the model can become more equitable in its decisions. Be aware though that humans have their own biases, so guardrails must always take this into consideration.
